# -*- coding: utf-8 -*-
"""IA2-PA-LVADSUSR124-SUSHIL-randomforest

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l3cEE_sz3XTDGNwTn63zbhZk3Y92UiKT
"""

import pandas as pd
df=pd.read_csv("https://raw.githubusercontent.com/Deepsphere-AI/LVA-Batch4-Assessment/main/winequality-red.csv")
print(df.isnull().sum())
## we can see that the data has missing or null values
df=df.fillna(df.mean())
## we have fixed or refilled oll the missing values using mean
print("------------------after filling missing value---------------")
print(df.isnull().sum())

## removing of the outliners

import seaborn as sns
sns.boxplot(df["total sulfur dioxide"])

q1=df["total sulfur dioxide"].quantile(0.25)
q3=df["total sulfur dioxide"].quantile(0.75)
iqr=q3-q1
lower=q1-(1.5*iqr)
upper=q3+(1.5*iqr)
outliner=((df["total sulfur dioxide"]<lower)|(df["total sulfur dioxide"]>120))
print(outliner)
df=df[~outliner]
sns.boxplot(df["total sulfur dioxide"])

import seaborn as sns
sns.boxplot(df["density"])

q1=df["density"].quantile(0.25)
q3=df["density"].quantile(0.75)
iqr=q3-q1
lower=q1-(1.5*iqr)
upper=q3+(1.5*iqr)
outliner=((df["density"]<lower)|(df["density"]>q3))
print(outliner)
df=df[~outliner]
import seaborn as sns
sns.boxplot(df["density"])

import seaborn as sns
sns.boxplot(df["residual sugar"])

q1=df["residual sugar"].quantile(0.25)
q3=df["residual sugar"].quantile(0.75)
iqr=q3-q1
lower=q1-(1.5*iqr)
upper=q3+(1.5*iqr)
outliner=((df["residual sugar"]<lower)|(df["residual sugar"]>q3))
print(outliner)
df=df[~outliner]
import seaborn as sns
sns.boxplot(df["residual sugar"])

## transforming of data
df.loc[df['quality'] <= 6, 'quality'] = 0
df.loc[df['quality'] > 6, 'quality'] = 1

## encoding of data
## we need not to perform any encoding since we already have all datas in numeric

## removing duplicates
print(~df.duplicated())
df.drop_duplicates()

## there is no categorical feature

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(df.drop('quality',axis='columns'),df['quality'],test_size=0.3)

from sklearn.ensemble import RandomForestClassifier

clf = RandomForestClassifier(n_estimators=100, random_state=42)

clf.fit(x_train, y_train)
predictions = clf.predict(x_test)

from sklearn.metrics import accuracy_score, precision_score, recall_score

accuracy = accuracy_score(y_test, predictions)
print("Accuracy:", accuracy*100)
prec = precision_score(y_test, predictions)
print("Precision:", prec*100)
recall = recall_score(y_test, predictions)
print("Recall:", recall*100)