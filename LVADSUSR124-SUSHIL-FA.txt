# -*- coding: utf-8 -*-
"""LVADSUSR124-SUSHIL-FA

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XV3R4YeXsezhL_FsWTBOjTZc3yqD4L7D
"""



import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

## 1
df=pd.read_excel("/content/Walmart_Dataset Python_Final_Assessment.xlsx")
df.info()
df.describe()

## 2
print(df[df.duplicated()])## this dataset contains zero duplicate values
print(df.count())
df.dropna()
df.count()## in the above script we used df.count() and now after droping we used df.count and counted the rows it is not affecte
## which indicates that the table does not have any missing values

## 3

walmartdatas=pd.read_excel("/content/Walmart_Dataset Python_Final_Assessment.xlsx")
print("basic analysis :","\n",walmartdatas.describe())
## it displays all the possible measures for data available in the dataframe
class measure_analysation:
  def __init__(self,df):
    self.df=df
  def geography(self):
    df=self.df
    df1=df.groupby("Geography").aggregate({"Profit":"mean"})
    df1=df1.sort_values("Profit",ascending=False)
    print(df1.tail())
  def geography_sales(self):
    df=self.df
    df1=df.groupby("Geography").aggregate({"Sales":"mean"})
    df1=df1.sort_values("Sales",ascending=False)
    print(df1.tail())
  def category_profit(self):
    category=self.df.groupby(self.df["Category"]).aggregate({"Profit":"sum"})
    category=category.sort_values("Profit",ascending=False)
    print(category.head())
  def category_sales(self):
    category=self.df.groupby(self.df["Category"]).aggregate({"Sales":"mean"})
    category=category.sort_values("Sales",ascending=False)
    print(category.head())
  def category_wise_count(self):
    category=self.df.groupby(self.df["Category"]).aggregate({"Product Name":"count"})
    print(category)
  def order_id_count (self):
    category=self.df.groupby(self.df["Order ID"]).aggregate({"Product Name":"count"})
    category=category.sort_values("Product Name",ascending=False)
    print(category.head())

## geography with mean of profit(we displayed least 5 average)
objs=measure_analysation(walmartdatas)
objs.geography()

# geography with mean of sales(we displayed least 5 average)
objs=measure_analysation(walmartdatas)
objs.geography_sales()

## top 5 highest profit is found through aggregate funcitons based on category
objs=measure_analysation(walmartdatas)
objs.category_profit()

## top 5 highest avergae sales  is found through aggregate funcitons based on category
objs=measure_analysation(walmartdatas)
objs.category_sales()

## here used aggregate function count to display the count of all the products in each category
objs=measure_analysation(walmartdatas)
objs. category_wise_count()

## using aggregate funciton count found the top 5 customer who order the most
objs=measure_analysation(walmartdatas)
objs. order_id_count()

## 4
walmartdata=pd.read_excel("/content/Walmart_Dataset Python_Final_Assessment.xlsx")

class walmart_analysis:
  def __init__(self,walmartdata):
    self.df=walmartdata
  def category_profit_analysis(self):
    category=df.groupby(self.df["Category"]).aggregate({"Profit":"sum"})
    sns.barplot(y="Category",x="Profit",data=category)
  def category_sales_analysis(self):
    category=df.groupby(self.df["Category"]).aggregate({"Sales":"sum"})
    sns.barplot(y="Category",x="Sales",data=category)
  def year_wise_profit(self):
    self.df["Ship Date"]=pd.to_datetime(self.df["Ship Date"])
    self.df["year"]=self.df["Ship Date"].dt.year
    year=df.groupby(self.df["year"]).aggregate({"Profit":"sum"})
    sns.barplot(x="year",y="Profit",data=year)
  def year_wise_Sales(self):
    self.df["Ship Date"]=pd.to_datetime(self.df["Ship Date"])
    self.df["year"]=self.df["Ship Date"].dt.year
    year=df.groupby(self.df["year"]).aggregate({"Sales":"sum"})
    sns.barplot(x="year",y="Sales",data=year)
  def category_analysis(self):
    category=df.groupby(self.df["Category"]).aggregate({"Profit":"sum","Sales":"sum"})
    fig,axes=plt.subplots(1,2)
    sns.lineplot(x="Category",y="Profit",data=category,ax=axes[0])
    sns.lineplot(x="Category",y="Sales",data=category,ax=axes[1])
  def category_wise_quantity_heatmap(self):

    category=self.df.pivot_table(index="Category",values="Quantity",aggfunc="sum")
    sns.heatmap(category,annot=True)




obj=walmart_analysis(walmartdata)
obj.category_wise_quantity_heatmap()

## category wise profit visualization
obj=walmart_analysis(walmartdata)
obj.category_profit_analysis()

## category wise sales visualization
obj=walmart_analysis(walmartdata)
obj.category_sales_analysis()

##category wise analysis with quantity in heatmap
obj=walmart_analysis(walmartdata)
obj.category_wise_quantity_heatmap()

## year wise profit visualization
obj=walmart_analysis(walmartdata)

obj.year_wise_profit()

## year wise sales visualization
obj=walmart_analysis(walmartdata)
obj.year_wise_Sales()

## category sales and profit
obj=walmart_analysis(walmartdata)
obj.category_analysis()

## 5
## correlation between quantity and profit for each category
df=pd.read_excel("/content/Walmart_Dataset Python_Final_Assessment.xlsx")
df1=df.groupby("Category").aggregate({"Quantity":"sum","Profit":"sum"})
print(df1.corr())
sns.heatmap(df1.corr(),annot=True)
plt.show()
## here in the output we can see that the both quantity and profit are partialy corelatted which means that they are not competely dependent
## but they are dependent

## correlation between sales and profit for each category
df=pd.read_excel("/content/Walmart_Dataset Python_Final_Assessment.xlsx")
df1=df.groupby("Category").aggregate({"Sales":"sum","Profit":"sum"})
print(df1.corr())
sns.heatmap(df1.corr(),annot=True)
plt.show()
## based on this output sales and profit are not mostly dependent on each other

## correlation between countries and order count for each category
df=pd.read_excel("/content/Walmart_Dataset Python_Final_Assessment.xlsx")
df1=df.groupby("Geography").aggregate({"Order ID":"count","Quantity":"sum"})
print(df1.corr())
sns.heatmap(df1.corr(),annot=True)
plt.show()
## here from this output you can see that the count of order id is completely dependent on quantity

## 6
## outliners in sales Category wise
df=pd.read_excel("/content/Walmart_Dataset Python_Final_Assessment.xlsx")
df1=df.groupby("Category").aggregate({"Sales":"sum","Quantity":"sum"})
fig,axes=plt.subplots(1,2,figsize=(10,6))
sns.boxplot(x="Category",y="Sales",data=df1,ax=axes[0])
sns.scatterplot(x="Category",y="Sales",data=df1,ax=axes[1])## because it has large number of data used scatter plot to find the outliners
## both chart are of the same axis and values
plt.show()

## outliners in Profit Category wise
df=pd.read_excel("/content/Walmart_Dataset Python_Final_Assessment.xlsx")
df1=df.groupby("Category").aggregate({"Profit":"sum"})
fig,axes=plt.subplots(1,2,figsize=(10,6))
sns.boxplot(x="Category",y="Profit",data=df1,ax=axes[0])
sns.scatterplot(x="Category",y="Profit",data=df1,ax=axes[1])## because it has large number of data used scatter plot to find the outliners
## both chart are of the same axis and values
plt.show()

## 7
##(i)
df['Order Date'] = pd.to_datetime(df['Ship Date'])
df.set_index('Ship Date', inplace=True)
yearly_data = df.resample('Y').sum()
plt.figure(figsize=(10, 6))
plt.plot(yearly_data.index.year, yearly_data['Sales'], label='Sales')
plt.plot(yearly_data.index.year, yearly_data['Profit'], label='Profit')
plt.xlabel('Year')
plt.ylabel('Amount')
plt.title('Sales and Profit Trends Over Years')
plt.legend()
plt.grid(True)
plt.show()

## 7
##(ii)
df['Order Date'] = pd.to_datetime(df['Order Date'])

df['Year'] = df['Order Date'].dt.year
df_growth = df.groupby('Category', group_keys=True)['Sales'].apply(lambda x: x.pct_change(1))

df_growth = df_growth.reset_index()
highest_growth_category = df_growth.groupby('Category')['Sales'].max().idxmax()
print("Category with most sales growth : ",highest_growth_category)

##(ii)
#ii.
category_sales = df.groupby(['Product Name', pd.to_datetime(df['Order Date']).dt.year])['Sales'].sum().unstack()

growth_rate = category_sales.pct_change(axis=1).iloc[:, 1:]
average_growth_rate = growth_rate.mean(axis=1)

most_growing_category = average_growth_rate.idxmax()

print("Category with the highest average growth rate: ",most_growing_category)

## 7
##(iii)

# Based on analysis done we can come to a conclusion
# (i)
# *We can find that in few contries doent contribute to profit where in inverse it contributes in the loss for the company
# *Also we are able to find that orders are mostly from few geographical area and most of the other countries does not contribute to the orders.
# *we are also able to find the churn rate which is low so there is no need to worry about the loyalty
# where as we need to work on improving the order rate of each customer
# (ii)
# factors influencing geographical sales there is certain category which gets more orders from certain area
# through which we can find the categories we need improvement in promotion of the particular category in the
# particular geographical area.
# (iii)
# *We can find that in few contries doent contribute to profit where in inverse it contributes in the loss for the company
# *Also we are able to find that orders are mostly from few geographical area and most of the other countries does not contribute to the orders.
# *we are also able to find the churn rate which is low so there is no need to worry about the loyalty